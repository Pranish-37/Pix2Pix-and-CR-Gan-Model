{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory\n",
    "base_dir = '/kaggle/input/pinku-dataset/Dataset'  # Replace with your actual dataset path\n",
    "\n",
    "# Create dataset instance\n",
    "brvo_dataset = BRVODataset(base_dir=base_dir)\n",
    "\n",
    "# Total number of image-label pairs\n",
    "print(f\"Total pairs in dataset: {len(brvo_dataset)}\")\n",
    "\n",
    "# Example of accessing an item\n",
    "image, label = brvo_dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Label shape: {label.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install ipywidgets matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels, kernel_size=4, stride=2, padding=1, batch_norm=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def upconv_block(in_channels, out_channels, kernel_size=4, stride=2, padding=1, dropout=False):\n",
    "            layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(0.5))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.encoder1 = conv_block(3, 64, batch_norm=False)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        self.encoder5 = conv_block(512, 512)\n",
    "        self.encoder6 = conv_block(512, 512)\n",
    "        \n",
    "        self.decoder1 = upconv_block(512, 512, dropout=True)\n",
    "        self.decoder2 = upconv_block(1024, 512, dropout=True)\n",
    "        self.decoder3 = upconv_block(1024, 256)\n",
    "        self.decoder4 = upconv_block(512, 128)\n",
    "        self.decoder5 = upconv_block(256, 64)\n",
    "        self.final_layer = nn.ConvTranspose2d(128, 1, 4, 2, 1)\n",
    "        self.final_act = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "        e6 = self.encoder6(e5)\n",
    "        \n",
    "        d1 = self.decoder1(e6)\n",
    "        d2 = self.decoder2(torch.cat([d1, e5], 1))\n",
    "        d3 = self.decoder3(torch.cat([d2, e4], 1))\n",
    "        d4 = self.decoder4(torch.cat([d3, e3], 1))\n",
    "        d5 = self.decoder5(torch.cat([d4, e2], 1))\n",
    "        \n",
    "        output = self.final_layer(torch.cat([d5, e1], 1))\n",
    "        return self.final_act(output)\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels, out_channels, kernel_size=4, stride=2, padding=1, batch_norm=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(4, 64, batch_norm=False),\n",
    "            conv_block(64, 128),\n",
    "            conv_block(128, 256),\n",
    "            conv_block(256, 512, stride=1),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize Models\n",
    "# Initialize Models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss and Optimizers\n",
    "criterion = nn.BCELoss()\n",
    "l1_loss = nn.L1Loss()  # L1 loss for generator\n",
    "lr_gen = 0.0002  # Learning rate for generator\n",
    "lr_disc = 0.0001  # Lowered learning rate for discriminator\n",
    "\n",
    "# Further increase lambda L1 weight to push for high contrast\n",
    "lambda_l1 = 200  # Increased for higher influence\n",
    "lambda_l2 = 10   # Optional weight for additional L2 loss if needed\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr_gen, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_disc, betas=(0.5, 0.999))\n",
    "\n",
    "# Learning rate schedulers\n",
    "scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=20, gamma=0.9)\n",
    "scheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=20, gamma=0.9)\n",
    "\n",
    "# Training Function with Final Loss Plot\n",
    "def train(dataloader, num_epochs, lambda_l1, lambda_l2):\n",
    "    d_losses, g_losses = [], []\n",
    "    \n",
    "    print(f\"Training for {num_epochs} epochs with Lambda L1 = {lambda_l1} and Lambda L2 = {lambda_l2}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        d_loss_epoch, g_loss_epoch = 0.0, 0.0\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            real_labels = torch.ones(images.size(0), 1, 30, 30).to(device)\n",
    "            fake_labels = torch.zeros(images.size(0), 1, 30, 30).to(device)\n",
    "\n",
    "            # Real loss\n",
    "            real_input = torch.cat([images, labels], dim=1)\n",
    "            real_output = discriminator(real_input)\n",
    "            d_real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_labels_pred = generator(images)\n",
    "            fake_input = torch.cat([images, fake_labels_pred], dim=1)\n",
    "            fake_output = discriminator(fake_input.detach())\n",
    "            d_fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "            # Total Discriminator Loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            d_loss_epoch += d_loss.item()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            fake_output = discriminator(fake_input)\n",
    "            # GAN loss\n",
    "            gan_loss = criterion(fake_output, real_labels)\n",
    "            # Pixel-wise L1 loss\n",
    "            l1_term = lambda_l1 * l1_loss(fake_labels_pred, labels)\n",
    "            # Optional L2 (MSE) loss\n",
    "            l2_term = lambda_l2 * nn.MSELoss()(fake_labels_pred, labels)\n",
    "            \n",
    "            # Total Generator Loss\n",
    "            g_loss = gan_loss + l1_term + l2_term\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            g_loss_epoch += g_loss.item()\n",
    "        \n",
    "        # Adjust learning rates\n",
    "        scheduler_G.step()\n",
    "        scheduler_D.step()\n",
    "\n",
    "        # Append average epoch loss\n",
    "        d_losses.append(d_loss_epoch / len(dataloader))\n",
    "        g_losses.append(g_loss_epoch / len(dataloader))\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_losses[-1]:.4f}, G Loss: {g_losses[-1]:.4f}\")\n",
    "    \n",
    "    # Plot the final loss graph after training is complete\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label=\"Discriminator Loss\", color=\"red\")\n",
    "    plt.plot(g_losses, label=\"Generator Loss\", color=\"blue\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Generator and Discriminator Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `dataloader` is your DataLoader with (image, label) pairs\n",
    "train(dataloader, num_epochs=250, lambda_l1=lambda_l1, lambda_l2=lambda_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained generator model\n",
    "torch.save(generator.state_dict(), \"generator100.pth\")\n",
    "print(\"Generator model saved as 'generator.pth'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the generator model\n",
    "def load_generator_model(path=\"generator.pth\"):\n",
    "    generator = Generator().to(device)\n",
    "    generator.load_state_dict(torch.load(path, map_location=device))\n",
    "    generator.eval()  # Set to evaluation mode\n",
    "    return generator\n",
    "\n",
    "# Define the transformation for the input image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Adjust to your model's input size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Inference Function\n",
    "def generate_label(input_image_path, generator_model_path=\"generator100.pth\"):\n",
    "    # Load the trained generator\n",
    "    generator = load_generator_model(generator_model_path)\n",
    "    \n",
    "    # Load and preprocess the input image\n",
    "    input_image = Image.open(input_image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(input_image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Generate the label\n",
    "    with torch.no_grad():\n",
    "        generated_label_tensor = generator(input_tensor)\n",
    "\n",
    "    # Post-process the output (convert tensor to image)\n",
    "    generated_label_tensor = (generated_label_tensor.squeeze(0) * 0.5 + 0.5)  # Scale to [0,1]\n",
    "    generated_label_image = transforms.ToPILImage()(generated_label_tensor.cpu())\n",
    "\n",
    "    # Display the input image and the generated label side-by-side\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(input_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Generated Label\")\n",
    "    plt.imshow(generated_label_image, cmap=\"gray\")  # Assuming label is grayscale\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally save the generated label\n",
    "    generated_label_image.save(\"generated_label.png\")\n",
    "    print(\"Generated label saved as 'generated_label.png'.\")\n",
    "\n",
    "# Example usage:\n",
    "generate_label(\"/kaggle/input/pinku-dataset/Dataset/S3/s3t2/image/2/2_11460.jpg\")  # Replace with the path to your input image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to load and resize images to a fixed size\n",
    "def load_and_resize_image(image_path, size=(256, 256)):\n",
    "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
    "    image = image.resize(size, Image.LANCZOS)  # Use LANCZOS for high-quality downsampling\n",
    "    return np.array(image)\n",
    "\n",
    "# Paths to your images\n",
    "original_image_path = \"/kaggle/input/pinku-dataset/Dataset/S3/s3t2/label/2/2_11460.jpg\"\n",
    "generated_image_path = \"/kaggle/working/generated_label.png\"\n",
    "\n",
    "# Load and resize both images to the same size\n",
    "original_image = load_and_resize_image(original_image_path)\n",
    "generated_image = load_and_resize_image(generated_image_path)\n",
    "\n",
    "# Apply thresholding (binarize) to focus on structure\n",
    "# Apply binary thresholding to make images purely black and white\n",
    "threshold_value = 128\n",
    "original_binary = (original_image > threshold_value).astype(np.uint8)*255 \n",
    "generated_binary = (generated_image > threshold_value).astype(np.uint8)*255\n",
    "\n",
    "# Convert images to tensors after thresholding\n",
    "original_tensor = torch.tensor(original_binary /255)  # Normalize to [0, 1]\n",
    "generated_tensor = torch.tensor(generated_binary/255)  # Normalize to [0, 1]\n",
    "\n",
    "# Ensure tensors have the same shape\n",
    "assert original_tensor.shape == generated_tensor.shape, \"The images must have the same dimensions after resizing.\"\n",
    "\n",
    "# Re-calculate similarity metrics after thresholding\n",
    "mse_value = torch.mean((original_tensor - generated_tensor) ** 2).item()\n",
    "ssim_value = ssim(original_binary, generated_binary, data_range=255)\n",
    "cosine_similarity_value = torch.nn.functional.cosine_similarity(\n",
    "    original_tensor.view(-1), generated_tensor.view(-1), dim=0).item()\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_value:.4f}\")\n",
    "print(f\"Structural Similarity Index (SSIM): {ssim_value:.4f}\")\n",
    "print(f\"Cosine Similarity: {cosine_similarity_value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
